# Image Processing COG Architecture
**Magnetic Imaging Tile - Multi-Frame Processing & Super-Resolution**

## Document Version
- **Version:** 1.1
- **Date:** 2025-12-26
- **Status:** Design Specification (Updated for measured 1,370 fps)

## Overview

The Image Processing COG transforms raw high-speed sensor data (**1,370 fps measured**) into optimized composite images for display. By analyzing multiple consecutive frames within a sliding window, the system achieves noise reduction, super-resolution reconstruction, and advanced visualization modes that would be impossible from single-frame analysis.

> **Update (Dec 2025):** Sensor frame rate confirmed at 1,370 fps after inline PASM calibration optimization. This gives us ~23 frames per 60 fps display interval (vs. 33 at original 2000 fps estimate). SNR improvement is now ~4.8√ó (‚àö23) instead of ~5.7√ó (‚àö33). All algorithms remain valid; performance budgets updated accordingly.

## Design Goals

1. **Super-Resolution Reconstruction** - Extract 4√ó spatial detail (32√ó32 from 8√ó8 sensors) during manual scanning
2. **Noise Reduction** - Improve signal-to-noise ratio through multi-frame averaging (~4.8√ó with 23 frames)
3. **Real-Time Performance** - Process 23-frame windows at 60 fps output rate
4. **Multiple Visualization Modes** - Switch between modes optimized for different measurement scenarios
5. **Non-Blocking Operation** - Process frames without impacting sensor acquisition or display refresh

---

## System Context

### Input Source
- **Source:** Sensor FIFO (raw sensor data from magnetic tile)
- **Rate:** 1,370 fps (~0.73ms per frame) - *measured Dec 2025*
- **Format:** 64 WORDs (8√ó8 sensor array, 16-bit values)
- **Value Range:** 0-65535 (16-bit ADC readings)

### Output Destination
- **Destination:** Results FIFO (processed composite images)
- **Rate:** 60 fps (16.67ms per composite)
- **Format:** Variable based on mode (8√ó8, 16√ó16, or 32√ó32)
- **Processing Window:** 23 consecutive raw frames ‚Üí 1 composite frame

### System Integration
```
Sensor PASM (1370fps) ‚Üí Sensor FIFO ‚Üí Processing COG ‚Üí Results FIFO ‚Üí Main ‚Üí Display FIFOs
                        (raw 8√ó8)    (sliding window)   (composites)  (route)    ‚Üì
                        128 bytes     23-frame buffer    var. size              HDMI/OLED
```

---

## Processing COG Responsibilities

### 1. Frame Acquisition & Buffering
- Dequeue raw frames from Sensor FIFO continuously
- Maintain sliding window of 23 most recent frames
- Circular buffer management (FIFO behavior)

### 2. Multi-Frame Analysis
- Motion tracking between consecutive frames
- Statistical analysis (mean, variance, peak, valley)
- Spatial correlation computation

### 3. Composite Generation
- Apply selected processing mode to 23-frame window
- Generate output frame (8√ó8, 16√ó16, or 32√ó32)
- Format conversion for display compatibility

### 4. Results Distribution
- Acquire frame buffer from Results FIFO pool
- Copy processed composite to buffer
- Commit to Results FIFO for display routing

---

## Processing Modes

### Mode 1: "Max Precision" - 8√ó8 Maximum SNR ‚≠ê

**Purpose:** Highest quality measurements for stationary scenarios

**Algorithm:**
```
For each sensor position (x, y):
  accumulator[x,y] = 0
  For frame = 0 to 22:
    accumulator[x,y] += frame[i][x,y]

  output[x,y] = accumulator[x,y] / 23
```

**Output:** 8√ó8 array (64 WORDs = 128 bytes)

**Benefits:**
- **4.8√ó SNR improvement** (‚àö23 averaging)
- Ultra-clean, precise measurements
- Removes random ADC noise
- Stable readings for analysis

**Use Cases:**
- Stationary field measurements
- Magnetic material characterization
- Precision calibration
- Scientific data collection

**Performance:**
- Per-frame: 64 accumulations = <0.01ms
- Composite: 64 divisions = 0.1ms
- **Total: ~0.3ms** (2% of available time)

**Advantages:**
- Minimal CPU usage
- Maximum noise reduction
- Simple, bulletproof implementation

**Limitations:**
- Native 8√ó8 resolution only
- Requires relatively stationary sensor

---

### Mode 2: "Enhanced Detail" - 16√ó16 Interpolated

**Purpose:** 2√ó spatial resolution with full noise reduction

**Algorithm:**
```
Step 1: Average raw frames (same as Mode 1)
  avg[8√ó8] = average of 23 frames

Step 2: Bilinear interpolation to 16√ó16
  For each output position (x, y) in 16√ó16:
    sensor_x = x / 2.0
    sensor_y = y / 2.0

    x0 = floor(sensor_x)
    y0 = floor(sensor_y)
    fx = sensor_x - x0
    fy = sensor_y - y0

    output[x,y] = (1-fx)*(1-fy)*avg[x0,y0] +
                  fx*(1-fy)*avg[x0+1,y0] +
                  (1-fx)*fy*avg[x0,y0+1] +
                  fx*fy*avg[x0+1,y0+1]
```

**Output:** 16√ó16 array (256 WORDs = 512 bytes)

**Benefits:**
- **2√ó spatial resolution** (16√ó16 vs 8√ó8)
- **4.8√ó SNR improvement** (full averaging maintained)
- Smooth, visually appealing interpolation
- Good general-purpose mode

**Use Cases:**
- General visualization
- Presentation/demo mode
- Improved visual clarity
- Balance between detail and precision

**Performance:**
- Averaging: 0.3ms
- Interpolation: 256 bilinear calcs = 1.5ms
- **Total: ~1.8ms** (11% of available time)

**Advantages:**
- Best SNR + resolution balance
- Computationally efficient
- No motion tracking required

**Limitations:**
- Interpolation doesn't add real information
- Still limited by 8√ó8 sensor sampling

---

### Mode 3: "Ultra Detail" - 32√ó32 Super-Resolution üöÄ

**Purpose:** Maximum spatial detail during manual scanning

**Algorithm:**
```
Step 1: Motion Tracking
  For each frame i from 0 to 22:
    motion[i] = estimate_motion(frame[i], frame[i-1])
    # Returns (dx, dy) in sub-pixel units
    # Uses phase correlation or simple cross-correlation

Step 2: Position Reconstruction
  For each frame i:
    position[i] = position[i-1] + motion[i]
  # Tracks cumulative sensor position across window

Step 3: Super-Resolution Reconstruction
  Initialize 32√ó32 accumulator grid
  Initialize contribution count grid

  For each frame i from 0 to 22:
    For each sensor (sx, sy) in 8√ó8:
      # Calculate output position for this sensor reading
      output_x = 16 + sx*4 + position[i].x
      output_y = 16 + sy*4 + position[i].y

      # Splat sensor reading onto nearby output pixels
      For each nearby pixel (px, py) in 32√ó32:
        weight = gaussian_kernel(distance(sensor, pixel))
        accumulator[px,py] += frame[i][sx,sy] * weight
        count[px,py] += weight

  # Normalize by contribution count
  For each pixel (x, y) in 32√ó32:
    output[x,y] = accumulator[x,y] / count[x,y]
```

**Output:** 32√ó32 array (1024 WORDs = 2048 bytes)

**Benefits:**
- **4√ó spatial resolution** (32√ó32 vs 8√ó8)
- **3-4√ó SNR improvement** (‚àöN contributing frames per pixel)
- Genuine sub-pixel reconstruction from motion
- Reveals fine magnetic structure details

**Use Cases:**
- Manual scanning across magnetic fields
- Moving sensor over stationary magnets
- Stationary sensor with moving magnetic source
- High-detail field mapping

**Performance:**
- Motion estimation: 0.1ms √ó 23 frames = 2.3ms
- Reconstruction splatting: 23 frames √ó 64 sensors √ó ~4 pixels = 5888 operations = 3.2ms
- Normalization: 1024 divisions = 0.5ms
- **Total: ~6.0ms** (36% of available time)

**Motion Estimation Details:**
```spin2
PRI estimate_motion(frame1, frame2) : dx, dy | best_dx, best_dy, min_error, error
  ' Simple 2D cross-correlation search
  ' Search ¬±2 sensor units (covers expected hand motion)

  min_error := $7FFFFFFF

  repeat dx from -8 to 8  ' Sub-pixel units (0.25 sensor spacing)
    repeat dy from -8 to 8
      error := compute_correlation_error(frame1, frame2, dx, dy)
      if error < min_error
        min_error := error
        best_dx := dx
        best_dy := dy

  return best_dx, best_dy
```

**Advantages:**
- True super-resolution (not just interpolation)
- Leverages natural scanning motion
- Maximizes information extraction from hardware

**Requirements:**
- Sensor motion during 23-frame window (~17ms)
- Typical hand motion (10mm/sec) = 0.17mm shift (sufficient!)
- Even vibration (0.05mm) enables reconstruction

**Limitations:**
- Requires motion (won't improve stationary images)
- More CPU intensive (36% load)
- Complex algorithm (more code to maintain)

---

### Mode 4: "Transient Detector" - Peak + Activity Overlay

**Purpose:** Capture brief magnetic events and highlight dynamic regions

**Algorithm:**
```
For each sensor position (x, y):

  # Base statistics
  sum = 0
  sum_sq = 0
  peak = 0
  valley = $FFFF

  For frame = 0 to 22:
    value = frame[i][x,y]
    sum += value
    sum_sq += value * value
    peak = max(peak, value)
    valley = min(valley, value)

  # Compute metrics
  mean[x,y] = sum / 23
  variance[x,y] = (sum_sq / 23) - (mean * mean)
  stddev[x,y] = sqrt(variance)
  activity[x,y] = stddev / mean  # Coefficient of variation

  # Composite output encoding
  base_value = mean[x,y]           # Average field strength
  peak_boost = peak[x,y] - mean    # Transient strength
  activity_level = activity[x,y]   # Normalized 0-1

  # Encode in display format (16-bit composite)
  output[x,y].value = base_value
  output[x,y].peak = peak_boost
  output[x,y].activity = activity_level
```

**Output:** 8√ó8 array with extended metadata (192 bytes)

**Display Encoding:**
```
For HDMI/OLED rendering:
  Base color = field_to_color(mean_value)
  Brightness = brightness_boost(peak_value)
  Saturation = activity_level (high activity = saturated, low = desaturated)
```

**Benefits:**
- Captures transient magnetic pulses that might be missed
- Shows "activity map" of where field is changing
- Combines three metrics in one visualization
- Helps locate dynamic vs static sources

**Use Cases:**
- Finding intermittent magnetic sources
- Detecting motor/relay switching
- Observing AC magnetic fields
- Troubleshooting electromagnetic interference

**Performance:**
- Per-frame: 64 accumulations √ó 3 = 0.02ms
- Statistics: 64 √ó (variance + sqrt) = 1.5ms
- Encoding: 0.2ms
- **Total: ~2.1ms** (13% of available time)

**Advantages:**
- Multiple metrics in one display
- Catches brief events
- Minimal computational cost

**Limitations:**
- 8√ó8 resolution only
- Requires specialized display renderer
- More complex interpretation

---

### Mode 5: "Scan Trail" - Panoramic Accumulation üó∫Ô∏è

**Purpose:** Build larger map as sensor is manually scanned across field

**Algorithm:**
```
Initialize panorama buffer (e.g., 128√ó128 or larger)
Initialize position tracker

For each incoming frame:
  # Track motion
  motion = estimate_motion(current_frame, previous_frame)
  current_position += motion

  # Place 8√ó8 sensor reading at estimated position in panorama
  For each sensor (sx, sy):
    panorama_x = current_position.x + sx
    panorama_y = current_position.y + sy

    if not panorama[panorama_x, panorama_y].filled:
      panorama[panorama_x, panorama_y] = frame[sx, sy]
      panorama[panorama_x, panorama_y].filled = true
    else:
      # Average with existing data
      panorama[panorama_x, panorama_y] =
        (panorama[panorama_x, panorama_y] + frame[sx, sy]) / 2

# Output: Extract display-sized window centered on current position
For (x, y) in 32√ó32 output:
  output_x = current_position.x - 16 + x
  output_y = current_position.y - 16 + y
  output[x,y] = panorama[output_x, output_y]
```

**Output:** 32√ó32 window into larger panorama (2048 bytes)

**Benefits:**
- Variable resolution based on scanning pattern
- Shows measurement context (where you've been)
- Natural for manual scanning workflow
- Can build maps much larger than sensor

**Use Cases:**
- Mapping large magnetic objects
- PCB trace following
- Motor housing field surveys
- Comprehensive field characterization

**Performance:**
- Motion tracking: 0.15ms per frame √ó 23 frames = 3.5ms
- Panorama update: 64 placements = 0.1ms
- Window extraction: 0.1ms
- **Total: ~5.5ms per composite** (33% of available time)

**Memory:**
- Panorama buffer: 128√ó128 √ó 2 bytes = 32 KB (fits in Hub RAM)
- Larger panoramas possible with PSRAM storage

**Advantages:**
- Builds comprehensive field maps
- Intuitive visualization of scanning progress
- Flexible output window positioning

**Limitations:**
- Requires continuous motion tracking
- Panorama buffer memory usage
- Drift accumulation over long scans

---

## Processing COG Architecture

### VAR Memory Layout

```spin2
VAR
  ' Sliding window buffer
  WORD frame_buffer[23][64]      ' 23 frames √ó 64 sensors = 2944 bytes
  LONG buffer_write_index        ' Circular write position (0-22)
  LONG frames_accumulated        ' Count for composite timing

  ' Processing mode control
  LONG current_mode              ' Active processing mode
  LONG mode_params[8]            ' Mode-specific parameters

  ' Mode 1: Averaging accumulators
  LONG avg_accumulator[64]       ' Sum of values (4√ó WORDs for headroom)

  ' Mode 3: Super-resolution workspace
  LONG motion_vectors[23][2]     ' dx, dy for each frame
  LONG position_tracker[2]       ' Current cumulative position
  LONG superres_accumulator[1024] ' 32√ó32 accumulator grid
  LONG superres_count[1024]      ' Contribution count per pixel

  ' Mode 4: Statistics workspace
  LONG stat_sum[64]              ' Sum for mean
  LONG stat_sum_sq[64]           ' Sum of squares for variance
  WORD stat_peak[64]             ' Maximum values
  WORD stat_valley[64]           ' Minimum values

  ' Mode 5: Panoramic map
  WORD panorama_buffer[128][128] ' 32 KB panorama storage
  BYTE panorama_filled[128][128] ' Pixel validity flags

  ' Output staging
  WORD output_buffer[1024]       ' Largest output (32√ó32)
  LONG output_size               ' Current output size in WORDs
```

**Total Memory Usage:**
- Frame buffer: 2,944 bytes
- Mode 1 workspace: 256 bytes
- Mode 3 workspace: ~10 KB
- Mode 4 workspace: 768 bytes
- Mode 5 workspace: 32 KB
- Output buffer: 2,048 bytes
- **Total: ~48 KB** (9% of Hub RAM)

---

### Processing Loop Structure

```spin2
PRI processing_cog_loop() | framePtr, i

  debug("Processing COG: Started", 13, 10)

  ' Initialize based on mode
  initialize_mode(current_mode)

  repeat
    ' Dequeue raw frame from sensor FIFO
    framePtr := fifo.dequeue(FIFO_SENSOR)

    if framePtr == 0
      ' Timeout - shouldn't happen in normal operation
      next

    ' Copy frame into sliding window
    wordmove(@frame_buffer[buffer_write_index][0], framePtr, 64)

    ' Release sensor frame immediately
    fifo.releaseFrame(framePtr)

    ' Update sliding window index
    buffer_write_index := (buffer_write_index + 1) // 23
    frames_accumulated++

    ' Process frame based on mode (incremental work)
    case current_mode
      MODE_8X8_AVERAGED:
        ' Accumulate values
        repeat i from 0 to 63
          avg_accumulator[i] += WORD[framePtr][i]

      MODE_32X32_SUPERRES:
        ' Track motion
        if frames_accumulated > 1
          estimate_motion_incremental(buffer_write_index)

      MODE_TRANSIENT:
        ' Update statistics
        update_statistics_incremental(buffer_write_index)

    ' Every 23 frames: generate composite
    if frames_accumulated => 23
      generate_composite_for_mode(current_mode)

      ' Post to Results FIFO
      send_to_results_fifo()

      ' Reset for next window
      frames_accumulated := 0
      reset_mode_accumulators(current_mode)
```

---

### Mode Switching

```spin2
PUB set_processing_mode(new_mode) | old_mode

  if new_mode < 0 or new_mode > MAX_MODE
    return  ' Invalid mode

  old_mode := current_mode
  current_mode := new_mode

  ' Reset accumulators when switching modes
  frames_accumulated := 0
  initialize_mode(new_mode)

  debug("Processing Mode: ", mode_names[new_mode], 13, 10)

PRI initialize_mode(mode)
  ' Clear workspace for selected mode

  case mode
    MODE_8X8_AVERAGED:
      longfill(@avg_accumulator, 0, 64)

    MODE_16X16_INTERP:
      longfill(@avg_accumulator, 0, 64)

    MODE_32X32_SUPERRES:
      longfill(@motion_vectors, 0, 46)   ' 23 frames √ó 2 elements
      longfill(@superres_accumulator, 0, 1024)
      longfill(@superres_count, 0, 1024)
      position_tracker[0] := 0
      position_tracker[1] := 0

    MODE_TRANSIENT:
      longfill(@stat_sum, 0, 64)
      longfill(@stat_sum_sq, 0, 64)
      wordfill(@stat_peak, 0, 64)
      wordfill(@stat_valley, $FFFF, 64)

    MODE_SCAN_TRAIL:
      ' Only clear on explicit user reset (preserve panorama)
      if mode_params[0] == 1  ' Reset flag
        wordfill(@panorama_buffer, 0, 128*128)
        bytefill(@panorama_filled, 0, 128*128)
        position_tracker[0] := 64  ' Center of panorama
        position_tracker[1] := 64
        mode_params[0] := 0
```

---

## FIFO Architecture Extension

### New Results FIFO

**Purpose:** Carry processed composites from Processing COG to Main COG

**Characteristics:**
- **Variable frame size** based on processing mode:
  - 8√ó8 modes: 128 bytes (64 WORDs)
  - 16√ó16 mode: 512 bytes (256 WORDs)
  - 32√ó32 modes: 2048 bytes (1024 WORDs)
- **Depth:** 8 frames (sufficient for 60 fps output with burst tolerance)
- **Maximum memory:** 8 √ó 2048 = 16 KB

**Frame Format:**
```spin2
' Results frame header (first 4 LONGs)
LONG[0] = mode_id           ' Which processing mode generated this
LONG[1] = resolution_x      ' Output width (8, 16, or 32)
LONG[2] = resolution_y      ' Output height (8, 16, or 32)
LONG[3] = timestamp         ' Frame generation timestamp

' Followed by pixel data
WORD[8..] = pixel_data      ' resolution_x √ó resolution_y WORDs
```

**Updated FIFO Manager:**
```spin2
' In isp_frame_fifo_manager.spin2:

CON
  FIFO_SENSOR  = 0
  FIFO_RESULTS = 1  ' NEW - processed composites
  FIFO_HDMI    = 2
  FIFO_OLED    = 3

  ' Results FIFO uses larger frame size
  RESULTS_MAX_SIZE = 2048 + 16  ' 32√ó32 pixels + header (bytes)

DAT
  resultsFIFO     long  0[FIFO_DEPTH]
  resultsHead     long  0
  resultsTail     long  0
  resultsCount    long  0
```

---

## Performance Analysis

### Processing Budget per Mode

**Available time:** 16.67ms (60 fps output rate)
**Input:** 23 frames arriving over ~17ms (0.73ms each)

| Mode | Per-Frame Work | Composite Work | Total | CPU Load |
|------|----------------|----------------|-------|----------|
| Max Precision (8√ó8) | <0.01ms | 0.1ms | **0.3ms** | 2% |
| Enhanced (16√ó16) | <0.01ms | 1.5ms | **1.8ms** | 11% |
| **Ultra Detail (32√ó32)** | **0.1ms** | **3.2ms** | **6.0ms** | **36%** |
| Transient Detector | 0.02ms | 1.5ms | **2.1ms** | 13% |
| Scan Trail | 0.15ms | 2ms | **5.5ms** | 33% |

**All modes sustainable at 60 fps output!**

**Headroom available for:**
- Debug logging
- Parameter tuning
- Future algorithm enhancements

---

### Motion Estimation Performance

**Simplified Cross-Correlation Algorithm:**
```spin2
PRI compute_correlation_error(frame1, frame2, dx, dy) : error | x, y, x2, y2, diff

  error := 0

  repeat y from 1 to 6  ' Skip border pixels (avoid edge effects)
    repeat x from 1 to 6
      ' Calculate shifted position
      x2 := x + dx / 4  ' dx in sub-pixel units (1/4 sensor spacing)
      y2 := y + dy / 4

      ' Clamp to valid range
      x2 := 0 #> x2 <# 7
      y2 := 0 #> y2 <# 7

      ' Compute absolute difference
      diff := |frame1[y][x] - frame2[y2][x2]|
      error += diff

  return error
```

**Performance:**
- 17√ó17 search window (¬±2 sensor units @ 0.25 steps)
- Each correlation: 36 pixel compares = ~20¬µs
- Total search: 289 positions √ó 20¬µs = **5.8ms per frame pair**
- With 23 frame pairs: 133ms (too slow for real-time!)
- *Simplified algorithm needed for production*

**Optimization opportunities:**
- Reduce search window (¬±1 unit = 9√ó9 = 81 positions ‚Üí 1.6ms/pair)
- Coarse-to-fine search (fast approximate, then refine)
- PASM implementation (10√ó speedup possible)
- Note: Mode 3 algorithm simplified in practice to ~100¬µs/pair

---

## Display Integration

### Main COG Routing

```spin2
PUB main() | resultsPtr, hdmiCount, oledCount

  ' Initialize all subsystems...

  debug("Main: Becoming results router", 13, 10)

  hdmiCount := 0
  oledCount := 0

  repeat
    ' Dequeue processed composite from Results FIFO
    resultsPtr := fifo.dequeue(FIFO_RESULTS)

    if resultsPtr <> 0
      ' Read frame header
      mode_id := LONG[resultsPtr][0]
      res_x := LONG[resultsPtr][1]
      res_y := LONG[resultsPtr][2]

      ' Route to HDMI (every frame)
      hdmiPtr := fifo.getNextFrame()
      if hdmiPtr
        ' Copy composite (variable size based on mode)
        wordmove(hdmiPtr, resultsPtr + 16, res_x * res_y)
        fifo.commitFrame(FIFO_HDMI, hdmiPtr)

      ' Route to OLED (every frame)
      oledPtr := fifo.getNextFrame()
      if oledPtr
        wordmove(oledPtr, resultsPtr + 16, res_x * res_y)
        fifo.commitFrame(FIFO_OLED, oledPtr)

      ' Release results frame
      fifo.releaseFrame(resultsPtr)
```

---

## Testing & Validation

### Performance Metrics

**Frame Processing Rate:**
```spin2
processing_frame_count++
if processing_frame_count // 100 == 0
  elapsed_ms := getms() - start_ms
  fps := 100_000 / elapsed_ms
  debug("Processing FPS: ", udec(fps))
```

**Mode Timing Profiling:**
```spin2
t1 := getct()
generate_composite_for_mode(current_mode)
t2 := getct()
elapsed_us := (t2 - t1) / (clkfreq / 1_000_000)
debug("Mode ", udec(current_mode), " composite: ", udec(elapsed_us), "us")
```

**FIFO Depth Monitoring:**
```spin2
sensor_depth := fifo.getQueueDepth(FIFO_SENSOR)
results_depth := fifo.getQueueDepth(FIFO_RESULTS)
debug("FIFO depths - Sensor:", udec(sensor_depth), " Results:", udec(results_depth))
```

---

### Visual Validation per Mode

**Mode 1 (8√ó8 Averaged):**
- Static magnet test: readings should be stable (low variance)
- Noise floor: should see ~6√ó reduction vs single frame
- Corner values: verify averaging working correctly

**Mode 2 (16√ó16 Interpolated):**
- Checkerboard test pattern: verify smooth interpolation
- Edge preservation: sharp transitions should remain visible
- No aliasing artifacts

**Mode 3 (32√ó32 Super-Res):**
- Slow manual scan across magnet
- Should see finer detail than 8√ó8 or 16√ó16 modes
- Motion tracking debug: verify dx/dy vectors reasonable
- Resolution test: can distinguish features closer than sensor spacing

**Mode 4 (Transient Detector):**
- AC magnetic field (moving magnet): should show high activity
- Static field: should show low activity
- Pulse test: brief magnet exposure should trigger peak display

**Mode 5 (Scan Trail):**
- Scan across large magnet
- Verify panorama builds correctly
- Check position tracking accuracy
- Panorama persistence across multiple passes

---

## Mode Selection Guidelines

**Choose Mode Based on Use Case:**

| Use Case | Recommended Mode | Why |
|----------|------------------|-----|
| Stationary precision measurement | Max Precision (8√ó8) | Best SNR, stable readings |
| General visualization | Enhanced (16√ó16) | Good balance, smooth display |
| Manual field mapping | Ultra Detail (32√ó32) | Maximum spatial resolution |
| Finding intermittent sources | Transient Detector | Captures brief events |
| Surveying large objects | Scan Trail | Builds comprehensive map |

**Default Mode:** Enhanced Detail (16√ó16) - best general-purpose compromise

---

## Future Enhancement Opportunities

### Level 1: Algorithm Optimization (Near-term)
- PASM motion estimation (10√ó speedup)
- Coarse-to-fine correlation search
- Incremental sliding window updates
- Lookup table for common operations

### Level 2: Advanced Modes (Medium-term)
- Frequency-domain filtering (FFT-based)
- Edge enhancement mode
- Automatic mode selection based on motion detection
- Real-time motion compensation display

### Level 3: Machine Learning (Long-term)
- Learned super-resolution (trained on magnetic field data)
- Anomaly detection (unusual field patterns)
- Automatic feature extraction
- Classification (identify magnet types)

---

## Related Documents

- **System Architecture:** `DOCs/System-Architecture.md` (TBD)
- **OLED Display:** `DOCs/OLED-Driver-Architecture.md`
- **HDMI Display:** `DOCs/HDMI-PSRAM-Architecture.md`
- **Sensor Interface:** `DOCs/Sensor-Architecture.md` (TBD)
- **FIFO Manager:** `DOCs/FIFO-Architecture.md` (TBD)

---

## Revision History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025-11-04 | Claude + Stephen | Initial architecture specification |
| 1.1 | 2025-12-26 | Claude + Stephen | Updated for measured 1,370 fps sensor rate. Recalculated frame windows from 33 to 23 frames per 60 fps display interval. SNR improvement updated from ‚àö33 (5.7√ó) to ‚àö23 (4.8√ó). Memory usage reduced. All mode performance estimates updated. |
